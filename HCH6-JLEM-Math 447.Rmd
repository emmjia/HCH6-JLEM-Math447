---
title: "Chapter 6 (8th Edition): 6.1, 6.3, 6.5, 6.6, 6.10, 6.11, 6.17, 6.22, 6.23, 6.25, 6.36, 6.37 "
author: "Jeremy Ling & Emmanuel Mejia"
date: "April 16, 2018"
output: pdf_document
---

```{r}
# loading libraries
library(car)
library(gplots)
```


##6.1

\textbf{An engineer is interested in the effects of cutting
speed (A), tool geometry (B), and cutting angle (C) on the life
(in hours) of a machine tool. Two levels of each factor are
chosen, and three replicates of a $2^3$ factorial design are run.
The results are as follows:}

\textbf{(a) Estimate the factor effects. Which effects appear to be
large?}

```{r}
# creating data table
factorA = rep(c("-","+","-","+","-","+","-","+"), times = 3)
factorB = rep(c("-","-","+","+","-","-","+","+"), times = 3)
factorC = rep(c("-","-","-","-","+","+","+","+"), times = 3)
Rep = rep(c("I", "II", "III"), each = 8)
yield = c(22,32,35,55,44,40,60,39,31,43,34,47,45,37,50,41,25,29,50,46,38,36,54,47)

cutting.speed.long = data.frame(factorA, factorB, factorC, Rep, yield)

# defining coded
coded=function(x) #a function to code variable x
{
  ifelse(x=="+", 1, -1)
}

# linear regression
cutting.speed.lm=lm(yield ~ coded(factorA) * coded(factorB) * coded(factorC), cutting.speed.long)
summary(cutting.speed.lm)

# interaction plot
with(cutting.speed.long, interaction.plot(factorA, factorC, yield))
```

The effects of tool geometry and cutting angle are statistically significant.  While cutting speed alone isn't statistically significant, its interaction with cutting angle is.  Therefore cutting speed should remain in the model.

\textbf{(b) Use the analysis of variance to confirm your conclusions
for part (a).}

```{r}
# ANOVA test
cutting.speed.aov=aov(yield ~ factorA * factorB * factorC, cutting.speed.long)
summary(cutting.speed.aov)
mse=summary(cutting.speed.aov)[[1]][8,3]
mse
```

The variables that we find statistically significant also match our results from estimating factor effects in part a.

\textbf{(c) Write down a regression model for predicting tool life
(in hours) based on the results of this experiment.}

$$y = \beta_0 + \beta_1 X_1 + \beta_2 + X_2 + \beta_3 + X_3 + \beta_{1,3} X_1 X_3$$


\textbf{(d) Analyze the residuals. Are there any obvious problems?}

```{r}
res=cutting.speed.long$yield-fitted(cutting.speed.lm)
qqPlot(res)
plot(fitted(cutting.speed.lm), res) 
```

We take a look at our normality plot and can state that normality is good. We take a look at our residual plot and see no patterns, our model is good.

\textbf{(e) On the basis of an analysis of main effect and interaction
plots, what coded factor levels of A, B, and C
would you recommend using?}

Because the coefficient for factorB is positive, cutting angle should be high.  In addition, the interaction plot reveals that lower cutting speed and higher life of a machine tool also produce a higher yield.


##6.3

\textbf{Find the standard error of the factor effects and
approximate 95 percent confidence limits for the factor effects
in Problem 6.1. Do the results of this analysis agree with the
conclusions from the analysis of variance?}

```{r}
#checking Standard error=sqrt(mse/N)
n=3;a=b=c=2;N=a*b*c*n
alpha=0.05
sqrt(mse/N)
#consturct CI for regression coefficient (example, for coded(A))
se=sqrt(mse/N)
df=a*b*c*(n-1)
hat.beta1=cutting.speed.lm$coefficients[2]
CI.beta=hat.beta1+c(-1,1)*qt(alpha/2,df,lower.tail = F)*se
CI.beta
2*CI.beta #CI for main effect A
```

Standard Error is 1.12 and the confidence interval for the factor effects are (-4.42, 5.0867).

##6.5

\textbf{A router is used to cut locating notches on a printed
circuit board. The vibration level at the surface of the board
as it is cut is considered to be a major source of dimensional
variation in the notches. Two factors are thought to influence vibration: bit size (A) and cutting speed (B). Two bit sizes (1/16
and 1/8 in.) and two speeds (40 and 90 rpm) are selected, and
four boards are cut at each set of conditions shown below.
The response variable is vibration measured as the resultant
vector of three accelerometers (x, y, and z) on each test circuit
board.}

\textbf{(a) Analyze the data from this experiment.}

```{r}
# creating data table
A <- rep(c("-","+","-","+"), times = 4)
B <- rep(c("-","-","+","+"), times = 4)
Rep <- rep(c("I","II","III","IV"), each = 4)
Vibes <- c(18.2, 27.2, 15.9, 41.0, 18.9, 24.0, 14.5, 43.9, 12.9, 22.4, 15.1, 36.3, 14.4, 22.5, 14.2, 39.9)
router.long <- data.frame(A, B, Rep, Vibes)

# defining coded
coded=function(x) #a function to code variable x
{
  ifelse(x=="+", 1, -1)
}

# linear regression
router.lm=lm(Vibes ~ coded(A) * coded(B), router.long)
summary(router.lm)
```

Our linear regression reveals that both treatments are statistically significant, with both variables positively correlated with vibration levels.  In addition, there is evidence of interaction between the two.

\textbf{(b) Construct a normal probability plot of the residuals,
and plot the residuals versus the predicted vibration
level. Interpret these plots.}

```{r}
router.aov = aov(Vibes ~ coded(A) * coded(B), router.long)
qqnorm(router.aov, full=T)
```

\textbf{(c) Draw the AB interaction plot. Interpret this plot. What
levels of bit size and speed would you recommend for
routine operation?}

```{r}
# interaction plot
with(router.long, interaction.plot(A, B, Vibes))
```

This plot reaffirms the notion that there is an interaction effect present between both variables.  We'd recommend a $\frac{1}{16}$ in. bit size and 40rpm speed to minimize vibrations in this operation.

##6.6

\textbf{Reconsider the experiment described in Problem 6.1.
Suppose that the experimenter only performed the eight trials
from replicate I. In addition, he ran four center points and
obtained the following response values: 36, 40, 43, 45.}

\textbf{(a) Estimate the factor effects. Which effects are large?}

```{r}
# defining coded
coded=function(x) #a function to code variable x
{
  ifelse(x=="+", 1, 
         ifelse(x == "0", 0, -1))
}

# creating data table
factorA <- c(coded(cutting.speed.long$factorA[1:8]), 0, 0, 0, 0)
factorB <- c(coded(cutting.speed.long$factorB[1:8]), 0, 0, 0, 0)
factorC <- c(coded(cutting.speed.long$factorC[1:8]), 0, 0, 0, 0)
yield <- c(cutting.speed.long[1:8, "yield"], 36, 40, 43, 45)

cutting.speed.small <- data.frame(cbind(factorA, factorB, factorC, yield))

# linear regression
cutting.speed.lm2=lm(yield ~ factorA * factorB * factorC + I(factorA^2) + I(factorB^2) + I(factorC^2), cutting.speed.small)

# interaction plot
with(cutting.speed.small, interaction.plot(factorA, factorC, yield))
  
summary(cutting.speed.lm2)
```

Our linear model reveals that our largest factor effects are exactly thhe same as those found in Problem 6.1.

\textbf{(b) Perform an analysis of variance, including a check for
pure quadratic curvature. What are your conclusions?}

```{r}
# center vs. factorial averages
yc_bar <- mean(cutting.speed.small$yield[9:12])
test <- mean(cutting.speed.small$yield[1:8])

# ANOVA test
cutting.speed.aov2 <- aov(yield ~ factorA * factorB * factorC + I(factorA^2) + I(factorB^2) + I(factorC^2), cutting.speed.small)
summary(cutting.speed.aov2)
```

The ANOVA test reveals that there is no statistically significant reason to suspect that there is any quadratic curvature in our model.

\textbf{(c) Write down an appropriate model for predicting tool
life, based on the results of this experiment. Does this
model differ in any substantial way from the model in
Problem 6.1, part (c)?}

Because we know that quadratic curvature should not be introduced to our model, our appropriate model is the same as in Problem 6.1.
$$y = \beta_0 + \beta_1 X_1 + \beta_2 + X_2 + \beta_3 + X_3 + \beta_{1,3} X_1 X_3$$

\textbf{(d) Analyze the residuals.}

```{r}
res=cutting.speed.small$yield-fitted(cutting.speed.lm2)
qqPlot(res)
plot(fitted(cutting.speed.lm2), res) 
```

There are patterns present, but this is due to the introduction of our 4 observations.

\textbf{(e) What conclusions would you draw about the appropriate
operating conditions for this process?}

Exactly like in Problem 6.1, a high cutting angle, low cutting speed, and high life of a machine tool will produce a higher yield.

##6.10

\textbf{In Problem 6.9, the engineer was also interested in
potential fatigue differences resulting from the two types of bottles.
As a measure of the amount of effort required, he measured
the elevation of the heart rate (pulse) induced by the task. The
results follow. Analyze the data and draw conclusions. Analyze
the residuals and comment on the model's adequacy.}

```{r}
# creating data table
type <- rep(c("Glass", "Plastic"), each = 4)
worker <- rep(c("1", "2"), each = 8)
pulse <- c(39, 45, 58, 35, 44, 35, 42, 21, 20, 13, 16, 11, 13, 10, 16, 15)
bottle.long <- data.frame(type, worker, pulse)

# interaction plot
with(bottle.long, interaction.plot(type, worker, pulse))

# defining coded
coded=function(x) #a function to code variable x
{
  ifelse(x=="Glass" | x=="1", 1, -1)
}

# linear regression
bottle.lm=lm(pulse ~ coded(type) * coded(worker), bottle.long)
summary(bottle.lm)

# ANOVA test
bottle.aov=aov(pulse ~ type * worker, bottle.long)
summary(bottle.aov)
mse=summary(bottle.aov)[[1]][4,3]
mse

# checking model adequacy
res=bottle.long$pulse-fitted(bottle.lm)
qqPlot(res)
plot(fitted(bottle.lm), res) 
```

When estimating factor effects, we don't suspect any interaction effects between bottle type and worker.  Both our linear model and ANOVA test suggest that worker is statistically significant in predicting heart rate when performing the task, and reaffirm the conclusion we made in our interaction plot.  When checking model adequacy, our qqplot reveals that our data is normally distributed, while the variances of residuals in our residual plot don't seem homogenous.  As a result, the model may not be adequate.

##6.11

\textbf{Calculate approximate 95 percent confidence limits
for the factor effects in Problem 6.10. Do the results of this
analysis agree with the analysis of variance performed in
Problem 6.10?}

```{r}
#checking Standard error=sqrt(mse/N)
n=4;a=b=2;N=a*b*n
alpha=0.05
sqrt(mse/N)
#consturct CI for regression coefficient (example, for coded(A))
se=sqrt(mse/N)
df=a*b*(n-1)

hat.beta1=bottle.lm$coefficients[2]
CI.beta=hat.beta1+c(-1,1)*qt(alpha/2,df,lower.tail = F)*se
CI.beta
2*CI.beta #CI for main effect A

hat.beta1=bottle.lm$coefficients[3]
CI.beta=hat.beta1+c(-1,1)*qt(alpha/2,df,lower.tail = F)*se
CI.beta
2*CI.beta #CI for main effect B

hat.beta1=bottle.lm$coefficients[4]
CI.beta=hat.beta1+c(-1,1)*qt(alpha/2,df,lower.tail = F)*se
CI.beta
2*CI.beta #CI for main effect AB
```

Confidence interval for main effect A is (-3.16, 13.4), for main effect B is (17.33, 33.91), and for interaction effect AB is (-4.66, 11.9). The only confidence interval the doesn't contain 0 is the one associated with 'worker'.  The results agree with those receive from the ANOVA test we ran earlier.

##6.17

\textbf{An experimenter has run a single replicate of a $2^4$
design. The following effect estimates have been calculated:}

\textbf{(a) Construct a normal probability plot of these effects.}

```{r}
letter = c("A","B","C","D","AB","AC","AD","BC","BD","CD","ABC","ABD","ACD","BCD","ABCD")
number = c(76.95,-67.52,-7.84,-18.73,-51.32,11.69,9.78,20.79,14.74,1.27,-2.82,-6.50,10.20,-7.98,-6.25)
experiment = data.frame(letter, number)

experiment.aov = aov(number ~ coded(letter), experiment)


plot = qqnorm(abs(number))
## click at the "outlier" points and then click "Finish" button


lister = sort(abs(number))

qqnorm(lister)
abline(h = 76.95, col = "red")
abline(h = 67.52, col = "purple")
abline(h = 51.32, col = "blue")
#factor A, B, and AB
```

\textbf{(b) Identify a tentative model, based on the plot of the
effects in part (a).}

$$\hat{y} = \beta_0 + 75.95x_a + 67.52x_b + 51.32x_{ab}$$



##6.22

\textbf{Semiconductor manufacturing processes have long
and complex assembly flows, so matrix marks and automated
2d-matrix readers are used at several process steps throughout
factories. Unreadable matrix marks negatively affect factory
run rates because manual entry of part data is required before
manufacturing can resume. A $2^4$ factorial experiment was conducted
to develop a 2d-matrix laser mark on a metal cover that
protects a substrate-mounted die. The design factors are A =
laser power (9 and 13 W), B = laser pulse frequency (4000 and
12,000 Hz), C = matrix cell size (0.07 and 0.12 in.), and D =
writing speed (10 and 20 in./sec), and the response variable is
the unused error correction (UEC). This is a measure of the
unused portion of the redundant information embedded in the
2d-matrix. A UEC of 0 represents the lowest reading that still
results in a decodable matrix, while a value of 1 is the highest
reading. A DMX Verifier was used to measure UEC. The data
from this experiment are shown in Table P6.5.}

```{r}
Standard.Order = c(8,10,12,9,7,15,2,6,16,13,5,14,1,3,4,11)
Run.Order = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16)
A = Laser.Power = c(1,1,1,-1,-1,-1,1,1,1,-1,-1,1,-1,-1,1,-1)
B = Pulse.Freq = c(1,-1,1,-1,1,1,-1,-1,1,-1,-1,-1,-1,1,1,1)
C = Cell.Size = c(1,-1,-1,-1,1,1,-1,1,1,1,1,1,-1,-1,-1,-1)
D = Writing.Speed = c(-1,1,1,1,-1,1,-1,-1,1,1,-1,1,-1,-1,-1,1)
UEC = c(0.8,0.81,0.79,0.6,0.65,0.55,0.98,0.67,0.69,0.56,0.63,0.65,0.75,0.72,0.98,0.63)
error = data.frame(Standard.Order,Run.Order,A,B,C,D,UEC)
```

\textbf{(a) Analyze the data from this experiment. Which factors
significantly affect UEC?}

```{r}
error.lm = lm(UEC ~A*B*C*D, error)
qqnorm(aov(UEC ~ A * B * C * D, error), label=T, full=T)
coef=error.lm$coefficients[-1]
variables=names(coef)
plot=qqnorm(coef)
variables[identify(plot)]


##new model
error.aov = aov(UEC ~ A+C+D, error)
summary(error.aov)
```

With the help of the normal probability plot we are able to identify that "A", "C", "D" are important. After choosing my factors, I plug them into a ANOVA and discover that all factors are significantly different.


\textbf{(b) Analyze the residuals from this experiment. Are there
any indications of model inadequacy?}

```{r}
error.lm2 = lm(UEC~ A*C*D, error)
res=error$UEC-fitted(error.lm2)
library(car)
qqPlot(res)
plot(fitted(error.lm2), res) 
```

After studying the normality and residuals we can state that normality is good and residuals are patternless and random. We may conclude that model is good.

##6.23

\textbf{Reconsider the experiment described in Problem 6.20.
Suppose that four center points are available and that the UEC
response at these four runs is 0.98, 0.95, 0.93, and 0.96, respectively.
Reanalyze the experiment incorporating a test for curvature
into the analysis. What conclusions can you draw? What
recommendations would you make to the experimenters?}

```{r}
Run = c(1,2,3,4,5,6,7,8)
A = c("-","+","-","+","-","+","-","+")
B = c("-","-","+","+","")
```

##6.25

\textbf{Consider the single replicate of the $2^4$ design in
Example 6.2. Suppose that we had arbitrarily decided to analyze
the data assuming that all three- and four-factor interactions
were negligible. Conduct this analysis and compare your
results with those obtained in the example. Do you think that
it is a good idea to arbitrarily assume interactions to be negligible
even if they are relatively high-order ones?}

```{r}
Run.Number = c(1:16)
Run.Label = c("(1)","a,","b","ab","C","ac","bc","abc","d","ad","bd","abd","cd","acd","bcd","abcd")
# creating data table
A <- rep(c("-", "+"), times = 8)
B <- rep(c("-", "+"), each = 2, times = 4)
C <- rep(c("-", "+"), each = 4, times = 2)
D <- rep(c("-", "+"), each = 8)
Filtration.Rate = c(45,71,48,65,68,60,80,65,43,100,45,104,75,86,70,96)
chem.long <- data.frame(Run.Number,A, B, C, D,Run.Label,Filtration.Rate)

# defining coded
coded=function(x) #a function to code variable x
{
  ifelse(x=="+", 1, -1)
}
```

##6.36

\textbf{Resistivity on a silicon wafer is influenced by several
factors. The results of a $2^4$ factorial experiment performed
during a critical processing step is shown in Table P6.10.}

\textbf{(a) Estimate the factor effects.  Plot the effect estimates on a normal probability plot and select a tentative model.}

```{r}
# creating data table
A <- rep(c("-", "+"), times = 8)
B <- rep(c("-", "+"), each = 2, times = 4)
C <- rep(c("-", "+"), each = 4, times = 2)
D <- rep(c("-", "+"), each = 8)
Resistivity <- c(1.92, 11.28, 1.09, 5.75, 2.13, 9.53, 1.03, 5.35, 1.60, 11.73, 1.16, 4.68, 2.16, 9.11, 1.07, 5.30)
wafer.long <- data.frame(Resistivity, A, B, C, D)

# defining coded
coded=function(x) #a function to code variable x
{
  ifelse(x=="+", 1, -1)
}

# linear regression
wafer.lm <- lm(Resistivity ~ coded(A) * coded(B) * coded(C) + coded(A) * coded(B) * coded(D) + coded(A) * coded(C) * coded(D) + coded(B) * coded(C) * coded(D), wafer.long)
summary(wafer.lm)

# normal probability plot
#plot = qqnorm(abs(number))
```

\textbf{(b) Fit the model identified in part (a) and analyze the residuals.  Is there any indication of model inadequacy.}

\textbf{(c) Repeat the analysis from parts (a) and (b) using ln(y) as the response variable.  Is there an indication that the transforation has been useful?}

\textbf{(d) Fit a model in terms of the coded variables that can be used to predict the resistivity.}

##6.37

\textbf{Continuation of Problem 6.36. Suppose that the
experimenter had also run four center points along with the 16
runs in Problem 6.36. The resistivity measurements at the center
points are 8.15, 7.63, 8.95, and 6.48. Analyze the experiment
again incorporating the center points. What conclusions
can you draw now?}

```{r}
# creating data table
A <- c(rep(c(-1, 1), times = 8), 0, 0, 0, 0)
B <- c(rep(c(-1, 1), each = 2, times = 4), 0, 0, 0, 0)
C <- c(rep(c(-1, 1), each = 4, times = 2), 0, 0, 0, 0)
D <- c(rep(c(-1, 1), each = 8), 0, 0, 0, 0)
Resistivity <- c(1.92, 11.28, 1.09, 5.75, 2.13, 9.53, 1.03, 5.35, 1.60, 11.73, 1.16, 4.68, 2.16, 9.11, 1.07, 5.30, 8.15, 7.63, 8.95, 6.48)
wafer.long2 <- data.frame(Resistivity, A, B, C, D)

# center vs. factorial averages
yc_bar <- mean(wafer.long2$Resistivity[1:16])
test <- mean(wafer.long2$Resistivity[17:20])

# linear regression
wafer.lm21 <- lm(Resistivity ~ A * B * C * D + I(A^2) + I(B^2) + I(C^2) + I(D^2), wafer.long2)
summary(wafer.lm21)

# ANOVA test
wafer.aov21 <- aov(Resistivity ~ A * B * C * D + I(A^2) + I(B^2) + I(C^2) + I(D^2), wafer.long2)
summary(wafer.aov21)

# checking model adequacy
res=wafer.long2$Resistivity-fitted(wafer.lm21)
qqPlot(res)
plot(fitted(wafer.lm21), res)

# Rebuild model
wafer.lm22 <- lm(Resistivity ~ A * B + I(A^2) + I(B^2), wafer.long2)
summary(wafer.lm22)

wafer.aov22 <- aov(Resistivity ~ A * B + I(A^2) + I(B^2), wafer.long2)
summary(wafer.aov22)

# checking model adequacy
res=wafer.long2$Resistivity-fitted(wafer.lm22)
qqPlot(res)
plot(fitted(wafer.lm22), res) 
```

With the introduction of center points to our dataset, we find that therer is statistically significant evidence of curvature in our model.  In addition, A, B, and AB are also statistically significant to our model. 